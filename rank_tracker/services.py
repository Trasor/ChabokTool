"""
Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Serper API Ùˆ Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø±ØªØ¨Ù‡
"""
import requests
import logging
from urllib.parse import urlparse
from django.conf import settings

logger = logging.getLogger(__name__)


class SerperService:
    """
    Ø³Ø±ÙˆÛŒØ³ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Serper.dev API Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†ØªØ§ÛŒØ¬ Google
    """
    API_KEY = '7ff1399efdf110530fed64f3742ed477de59e8e2'
    BASE_URL = 'https://google.serper.dev/search'

    def __init__(self):
        self.api_key = self.API_KEY

    def get_rank(self, keyword, target_domain):
        """
        Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø±ØªØ¨Ù‡ ÛŒÚ© Ø¯Ø§Ù…Ù†Ù‡ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ

        Args:
            keyword (str): Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø¬Ø³ØªØ¬Ùˆ
            target_domain (str): Ø¯Ø§Ù…Ù†Ù‡ Ù‡Ø¯Ù (Ù…Ø«Ø§Ù„: digikala.com)

        Returns:
            dict or None: {'rank': int, 'url': str, 'title': str} ÛŒØ§ None
        """
        try:
            payload = {
                "q": keyword,
                "gl": "ir",      # Ú©Ø´ÙˆØ±: Ø§ÛŒØ±Ø§Ù†
                "hl": "fa",      # Ø²Ø¨Ø§Ù†: ÙØ§Ø±Ø³ÛŒ
                "num": 100       # ØªØ¹Ø¯Ø§Ø¯ Ù†ØªØ§ÛŒØ¬: 100 (Ø¨Ø§ 1 Ú©Ø±Ø¯ÛŒØª!)
            }

            headers = {
                "X-API-KEY": self.api_key,
                "Content-Type": "application/json"
            }

            response = requests.post(
                self.BASE_URL,
                json=payload,
                headers=headers,
                timeout=30
            )

            if response.status_code != 200:
                logger.error(f"âœ— Serper API error: {response.status_code} - {response.text}")
                return None

            data = response.json()

            # Debug: Ù„Ø§Ú¯ Ú©Ø§Ù…Ù„ response Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ
            logger.debug(f"ğŸ“‹ Serper API full response for '{keyword}':")
            logger.debug(f"   Total organic results: {len(data.get('organic', []))}")
            if 'searchParameters' in data:
                logger.debug(f"   Search parameters: {data['searchParameters']}")

            result = self._find_domain_in_results(data, target_domain)

            if result:
                logger.info(f"âœ“ Found '{target_domain}' at rank {result['rank']} for keyword '{keyword}'")
                logger.debug(f"  URL: {result['url']}")
                logger.debug(f"  Title: {result['title']}")
            else:
                logger.warning(f"âš  Domain '{target_domain}' not found in top 100 for '{keyword}'")

            return result

        except requests.exceptions.Timeout:
            logger.error(f"âœ— Timeout while searching for '{keyword}'")
            return None
        except requests.exceptions.RequestException as e:
            logger.error(f"âœ— Request error for '{keyword}': {str(e)}")
            return None
        except Exception as e:
            logger.error(f"âœ— Unexpected error for '{keyword}': {str(e)}")
            return None

    def _find_domain_in_results(self, results, target_domain):
        """
        Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¯Ø§Ù…Ù†Ù‡ Ø¯Ø± Ù†ØªØ§ÛŒØ¬ organic

        Args:
            results (dict): Ù¾Ø§Ø³Ø® JSON Ø§Ø² Serper
            target_domain (str): Ø¯Ø§Ù…Ù†Ù‡ Ù‡Ø¯Ù

        Returns:
            dict or None: {'rank': int, 'url': str, 'title': str} ÛŒØ§ None
        """
        organic_results = results.get('organic', [])

        # Ù„Ø§Ú¯ ØªØ¹Ø¯Ø§Ø¯ Ù†ØªØ§ÛŒØ¬ Ø¯Ø±ÛŒØ§ÙØªÛŒ
        logger.info(f"ğŸ“Š Received {len(organic_results)} organic results from Serper API")

        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ù…Ù†Ù‡ Ù‡Ø¯Ù (Ø­Ø°Ù www Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ lowercase)
        target_domain_clean = target_domain.lower().replace('www.', '').strip().rstrip('/')

        # Ø§Ú¯Ù‡ Ø¯Ø§Ù…Ù†Ù‡ ÙÙ‚Ø· ÛŒÙ‡ Ú©Ù„Ù…Ù‡ Ø¨Ø§Ø´Ù‡ (Ù…Ø«Ù„ dncbot)ØŒ ÙÙ‚Ø· Ø¢Ù† Ø¨Ø®Ø´ Ø±Ø§ Ø¨Ú¯ÛŒØ±
        # Ù…Ø«Ø§Ù„: dncbot.ir -> dncbot
        target_base = target_domain_clean.split('.')[0] if '.' in target_domain_clean else target_domain_clean

        for index, result in enumerate(organic_results, start=1):
            link = result.get('link', '')
            title = result.get('title', 'Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†')

            if not link:
                continue

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ù…Ù†Ù‡ Ø§Ø² URL
            try:
                parsed = urlparse(link)
                result_domain = parsed.netloc.lower().replace('www.', '').strip()

                # Ú†Ù†Ø¯ Ø±ÙˆØ´ Ø¨Ø±Ø§ÛŒ match Ú©Ø±Ø¯Ù†:
                # 1. Ù…Ø·Ø§Ø¨Ù‚Øª Ú©Ø§Ù…Ù„ Ø¯Ø§Ù…Ù†Ù‡
                if target_domain_clean == result_domain:
                    return {'rank': index, 'url': link, 'title': title}

                # 2. ÛŒÚ©ÛŒ Ø²ÛŒØ±Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯ÛŒÚ¯Ø±ÛŒ Ø¨Ø§Ø´Ù‡ (Ø¨Ø±Ø§ÛŒ subdomain Ù‡Ø§)
                if target_domain_clean in result_domain or result_domain in target_domain_clean:
                    return {'rank': index, 'url': link, 'title': title}

                # 3. Ù…Ø·Ø§Ø¨Ù‚Øª base domain (Ù…Ø«Ù„Ø§ dncbot Ø¨Ø§ dncbot.ir)
                result_base = result_domain.split('.')[0] if '.' in result_domain else result_domain
                if target_base == result_base and len(target_base) > 3:  # Ø­Ø¯Ø§Ù‚Ù„ 4 Ú©Ø§Ø±Ø§Ú©ØªØ±
                    return {'rank': index, 'url': link, 'title': title}

            except Exception as e:
                logger.warning(f"âš  Failed to parse URL '{link}': {str(e)}")
                continue

        return None

    def get_bulk_ranks(self, keywords_dict):
        """
        Ø¯Ø±ÛŒØ§ÙØª Ø±ØªØ¨Ù‡ Ø¨Ø±Ø§ÛŒ Ú†Ù†Ø¯ÛŒÙ† Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ù‡ ØµÙˆØ±Øª ÛŒÚ©Ø¬Ø§

        Args:
            keywords_dict (dict): Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ {keyword: target_domain}

        Returns:
            dict: {keyword: rank}
        """
        results = {}
        for keyword, domain in keywords_dict.items():
            rank = self.get_rank(keyword, domain)
            results[keyword] = rank
        return results


class RankService:
    """
    Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø±ØªØ¨Ù‡ Ùˆ Ø¢Ù¾Ø¯ÛŒØª Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§
    """

    def __init__(self):
        self.serper = SerperService()

    def update_project_ranks(self, project):
        """
        Ø¢Ù¾Ø¯ÛŒØª Ø±ØªØ¨Ù‡ ØªÙ…Ø§Ù… Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ ÛŒÚ© Ù¾Ø±ÙˆÚ˜Ù‡

        Args:
            project: RankProject instance

        Returns:
            dict: Ù†ØªÛŒØ¬Ù‡ Ø¢Ù¾Ø¯ÛŒØª
        """
        from .models import RankProject
        import time

        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù…Ø§Ù‡Ø§Ù†Ù‡
        project.check_and_reset_monthly_counter()

        if not project.can_update:
            return {
                'status': 'failed',
                'error': 'Ù…Ø­Ø¯ÙˆØ¯ÛŒØª 4 Ø¢Ù¾Ø¯ÛŒØª Ø¯Ø± Ù…Ø§Ù‡ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯Ù‡ Ø§Ø³Øª.'
            }

        keywords = project.keywords.all()
        if not keywords.exists():
            return {
                'status': 'failed',
                'error': 'Ù¾Ø±ÙˆÚ˜Ù‡ Ù‡ÛŒÚ† Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ù†Ø¯Ø§Ø±Ø¯.'
            }

        updated_count = 0
        failed_count = 0

        for keyword in keywords:
            try:
                # ØªØ§Ø®ÛŒØ± 200ms Ø¨ÛŒÙ† Ù‡Ø± request (Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Rate Limit)
                time.sleep(0.2)

                # Ø¯Ø±ÛŒØ§ÙØª Ø±ØªØ¨Ù‡ Ø§Ø² Serper (Ø­Ø§Ù„Ø§ dict Ø¨Ø±Ù…ÛŒÚ¯Ø±Ø¯ÙˆÙ†Ù‡)
                result = self.serper.get_rank(keyword.keyword, project.target_domain)

                if result:
                    # Ø¢Ù¾Ø¯ÛŒØª Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø§ URL Ùˆ title
                    keyword.update_rank(
                        new_rank=result['rank'],
                        ranked_url=result.get('url'),
                        ranked_title=result.get('title')
                    )
                else:
                    # Ø±ØªØ¨Ù‡ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ null Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
                    keyword.update_rank(new_rank=None)

                updated_count += 1

            except Exception as e:
                logger.error(f"âœ— Failed to update keyword '{keyword.keyword}': {str(e)}")
                failed_count += 1
                continue

        # Ø¢Ù¾Ø¯ÛŒØª Ù¾Ø±ÙˆÚ˜Ù‡
        from django.utils import timezone
        project.update_count_current_month += 1
        project.last_update_at = timezone.now()
        project.save(update_fields=['update_count_current_month', 'last_update_at'])

        return {
            'status': 'success',
            'updated': updated_count,
            'failed': failed_count,
            'total': keywords.count()
        }

    def update_selected_keywords(self, project, keywords_queryset):
        """
        Ø¢Ù¾Ø¯ÛŒØª ÙÙ‚Ø· Ú©Ù„Ù…Ø§Øª Ø§Ù†ØªØ®Ø§Ø¨ÛŒ (Ø¨Ø¯ÙˆÙ† Ú©Ø³Ø± Ø§Ø² Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù…Ø§Ù‡Ø§Ù†Ù‡)

        Args:
            project: RankProject instance
            keywords_queryset: QuerySet of selected RankKeyword objects

        Returns:
            dict: Ù†ØªÛŒØ¬Ù‡ Ø¢Ù¾Ø¯ÛŒØª
        """
        import time

        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù…Ø§Ù‡Ø§Ù†Ù‡
        project.check_and_reset_monthly_counter()

        if not project.can_update:
            return {
                'status': 'failed',
                'error': 'Ù…Ø­Ø¯ÙˆØ¯ÛŒØª 4 Ø¢Ù¾Ø¯ÛŒØª Ø¯Ø± Ù…Ø§Ù‡ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯Ù‡ Ø§Ø³Øª.'
            }

        updated_count = 0
        failed_count = 0

        for keyword in keywords_queryset:
            try:
                # ØªØ§Ø®ÛŒØ± 200ms Ø¨ÛŒÙ† Ù‡Ø± request
                time.sleep(0.2)

                # Ø¯Ø±ÛŒØ§ÙØª Ø±ØªØ¨Ù‡ Ø§Ø² Serper
                result = self.serper.get_rank(keyword.keyword, project.target_domain)

                if result:
                    keyword.update_rank(
                        new_rank=result['rank'],
                        ranked_url=result.get('url'),
                        ranked_title=result.get('title')
                    )
                else:
                    keyword.update_rank(new_rank=None)

                updated_count += 1

            except Exception as e:
                logger.error(f"âœ— Failed to update keyword '{keyword.keyword}': {str(e)}")
                failed_count += 1
                continue

        # Ø¢Ù¾Ø¯ÛŒØª Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ (Ø­ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ø¯ÛŒØª Ø§Ù†ØªØ®Ø§Ø¨ÛŒ)
        from django.utils import timezone
        project.update_count_current_month += 1
        project.last_update_at = timezone.now()
        project.save(update_fields=['update_count_current_month', 'last_update_at'])

        return {
            'status': 'success',
            'updated': updated_count,
            'failed': failed_count,
            'total': keywords_queryset.count()
        }
